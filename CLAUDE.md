# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

<!-- 
IMPORTANT: This is a template CLAUDE.md file. For your project-specific instructions:
1. Copy this file and modify for your project needs
2. Keep Claude-Ops utility commands by including: 
   {% include "CLAUDE-OPS.md" %} or manually copy relevant sections
3. Replace the sections below with your project-specific guidance
-->

## Core System Principles (í”¼ë“œë°± ë°˜ì˜ ì™„ë£Œ)

- **Dual Architecture**: Notion is the strategic headquarters (Studio) managing "why" and "what", while Git/Terminal is the development workshop managing "how"
- All work starts from Notion `Task` tickets; all Git branches must be linked to Notion Task IDs
- Git branches follow naming convention: `feature/TID-XXXXXXXX-...` using real Notion TIDs
- Pull Requests are formal technical reports, not just code submissions
- **Output files follow the 'Output Management Principles' and must be managed via Git-LFS or shared NAS, ensuring code-result connectivity**
- **All exploration process records (AI conversation logs) must be archived in Notion Task anchor pages as STRUCTURED SUMMARIES - this serves as the research 'black box' for reproducibility and debugging**
- Knowledge follows the '4-stage Knowledge Creation Principles' detailed in `prompts/1_philosophy_knowledge_creation.md`. The `task publish` command executes the final stage

## ğŸ”§ í”¼ë“œë°± ë°˜ì˜ ê°œì„ ì‚¬í•­

### 1. Task ìƒíƒœ ê´€ë¦¬ ê°œì„ 
- `/task-finish` ëª…ë ¹ì–´ê°€ Notion ìƒíƒœë¥¼ "Done"ìœ¼ë¡œ ì •í™•íˆ ì—…ë°ì´íŠ¸
- ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„ ë° ì˜¤ë¥˜ ë³´ê³  í¬í•¨
- Notion API í˜¸ì¶œ ê²€ì¦ ë¡œì§ ê°•í™”

### 2. ëŒ€í™” ì•„ì¹´ì´ë¹™ ê°œì„   
- Raw ëŒ€í™” ë¡œê·¸ ëŒ€ì‹  **êµ¬ì¡°í™”ëœ ìš”ì•½** ìƒì„±
- ì£¼ìš” ì‘ì—… ë‚´ìš©, ì‚¬ìš©ì ìš”ì²­ì‚¬í•­, ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ ìë™ ì¶”ì¶œ
- ê°€ë…ì„± ë†’ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ Notionì— ì €ì¥

### 3. ì™„ì „ ìë™í™” ì›Œí¬í”Œë¡œìš°
- `--auto-merge` í”Œë˜ê·¸ë¡œ PR ìƒì„± â†’ ìë™ ë³‘í•© â†’ ë¸Œëœì¹˜ ì •ë¦¬
- Squash mergeë¡œ ê¹”ë”í•œ ì»¤ë°‹ íˆìŠ¤í† ë¦¬ ìœ ì§€
- ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ëª¨ë“œë¡œ fallback

### 4. êµ¬ì²´ì  ì‚°ì¶œë¬¼ ì •ì˜
- ê° Taskì— ëª…í™•í•œ deliverableê³¼ success criteria í¬í•¨
- PRDì™€ ì™„ì „ ì¼ì¹˜í•˜ëŠ” Epic/Task êµ¬ì¡°
- ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³¼ ì§€í‘œ (ì •í™•ë„, ì„±ëŠ¥, í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨ ë“±)

## API and Tool Information

Available tools: Notion API, GitHub API, local Git CLI, GitHub CLI (`gh`), and **Git-LFS CLI**

**Environment Configuration:**
Environment variables must be set in `.env` file (copy from `.env.example`):
- `NOTION_API_KEY`: Notion integration token
- `NOTION_TASKS_DB_ID`: Tasks database ID  
- `NOTION_PROJECTS_DB_ID`: Projects database ID
- `NOTION_KNOWLEDGE_HUB_ID`: Knowledge Hub page ID
- `GITHUB_PAT`: GitHub Personal Access Token
- `GITHUB_REPO_OWNER`: GitHub repository owner
- `GITHUB_REPO_NAME`: GitHub repository name

## Command Structure

### Core Workflow Commands (Claude Code Slash Commands) - í”¼ë“œë°± ë°˜ì˜ ì™„ë£Œ

- `/project-plan <file>`: Create Project â†’ Epic â†’ Task hierarchy in Notion from proposal documents
  - **ê°œì„ **: êµ¬ì²´ì  ì‚°ì¶œë¬¼ê³¼ ì„±ê³µê¸°ì¤€ í¬í•¨í•œ Task ìƒì„±
  - **ì˜ˆì‹œ**: `/project-plan docs/proposals/2025-07-24_improved-data-analysis-pipeline.md`

- `/task-start <TID>`: Start Notion task and create Git branch using real Notion TID  
  - **ê°œì„ **: UUID ìë™ í•´ì„ ë° ë¸Œëœì¹˜ ëª…ëª… ê·œì¹™ ì ìš©
  - **ì˜ˆì‹œ**: `/task-start 23a5d36f-fc73-81ff-8ced-f357b6b7a71b`

- `/task-archive [TID]`: Export conversation and create STRUCTURED SUMMARY in Notion Task page
  - **ê°œì„ **: Raw ë¡œê·¸ ëŒ€ì‹  êµ¬ì¡°í™”ëœ ìš”ì•½ ìƒì„± (ì£¼ìš” ì‘ì—…, ì‚¬ìš©ì ìš”ì²­, ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­)
  - **ìë™ ê°ì§€**: Git ë¸Œëœì¹˜ì—ì„œ TID ìë™ ì¶”ì¶œ
  - **ì˜ˆì‹œ**: `/task-archive` (í˜„ì¬ ë¸Œëœì¹˜ì—ì„œ ìë™)

- `/task-finish <TID> --pr [--auto-merge]`: Complete task with PR creation and optional auto-merge
  - **ì‹ ê·œ**: `--auto-merge` í”Œë˜ê·¸ë¡œ ì™„ì „ ìë™í™” (PR ìƒì„± â†’ ë³‘í•© â†’ ë¸Œëœì¹˜ ì •ë¦¬)
  - **ê°œì„ **: Notion ìƒíƒœ ì—…ë°ì´íŠ¸ ê²€ì¦ ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”
  - **ì˜ˆì‹œ**: `/task-finish <TID> --pr --auto-merge` (ê¶Œì¥)

- `/task-publish <TID>`: Publish completed task knowledge to Knowledge Hub

**ğŸš€ í”¼ë“œë°± ë°˜ì˜ í•µì‹¬ ê°œì„ ì‚¬í•­:**
- **ì™„ì „ ìë™í™”**: `--auto-merge`ë¡œ ê°œë°œì ê°œì… ìµœì†Œí™”
- **êµ¬ì¡°í™”ëœ ì•„ì¹´ì´ë¹™**: ê°€ë…ì„± ë†’ì€ ëŒ€í™” ìš”ì•½
- **ì •í™•í•œ ìƒíƒœ ê´€ë¦¬**: Notion API í˜¸ì¶œ ê²€ì¦ ë° ì¬ì‹œë„
- **êµ¬ì²´ì  ì‚°ì¶œë¬¼**: ê° Taskì— ëª…í™•í•œ deliverable ì •ì˜
- **ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥**: QUICK_START.mdë¡œ 5ë¶„ ë‚´ ì„¤ì • ì™„ë£Œ

### Pipeline Execution Commands
- `python main.py workflow-a --fastq-dir <dir> --reference-genome <file> --metadata <file>`: Run FASTQ-based pipeline
- `python main.py workflow-b --count-table <file> --metadata <file> --annotation <file>`: Run count table-based pipeline
- `python main.py results --outdir <dir>`: List and summarize pipeline results

### Development Commands

#### Python Development
```bash
# Install dependencies
uv sync

# Run the main application
python main.py

# Run with uv
uv run python main.py
```

#### Optional: Domain-Specific Tools

For computational workflows (when using Nextflow):
```bash
# Run pipeline locally
nextflow run src/main.nf -profile local

# Run on cluster
nextflow run src/main.nf -profile cluster

# Run with custom output directory
nextflow run src/main.nf --output_dir /path/to/results
```

## Claude Code Optimization Strategies

### ğŸš€ Tool Usage Optimization
- **Use Task tool for**: Complex analysis, multi-file searches, architectural reviews
- **Use MultiEdit for**: Batch refactoring, consistent style changes, pattern replacements  
- **Use Glob + batch Read**: When analyzing multiple files with similar patterns
- **Combine tools strategically**: Glob â†’ Task analysis â†’ MultiEdit implementation

### ğŸ“Š Context Management Best Practices
- **Batch similar operations**: Read multiple files in one go when possible
- **Use Task tool for heavy lifting**: Delegate complex analysis to reduce main context usage
- **Prioritize MultiEdit**: Single tool call vs multiple Edit calls saves significant tokens
- **Strategic file reading**: Read only necessary sections using offset/limit parameters

### âš¡ Performance Optimization Patterns
```python
# Efficient pattern: Batch processing
files = Glob("**/*.py")
for batch in chunk_files(files, 5):
    batch_analysis = Task(f"Analyze these {len(batch)} files for issues")
    apply_fixes_with_multiedit(batch, batch_analysis.fixes)

# Efficient pattern: Targeted operations  
critical_files = Glob("**/telegram/*.py") 
performance_issues = Task("Find performance bottlenecks in telegram modules")
MultiEdit(critical_files, performance_issues.suggested_changes)
```

## Architecture and Structure

### Directory Structure
- `CLAUDE.md`: Central guidance file for Claude Code automation
- `slash_commands/`: Claude Code slash command specifications
  - `project-plan.md`: `/project-plan` command specification
  - `task-start.md`: `/task-start` command specification  
  - `task-archive.md`: `/task-archive` command specification
- `src/`: Contains workflow management and optional domain-specific tools
  - `workflow_manager.py`: Core Notion-Git integration system
  - `workflows/`: Optional domain-specific pipeline implementations
  - `modules/`: Optional modular processes for domain workflows
  - `bin/`: Optional analysis scripts
  - `configs/`: Environment-specific configurations
- `data/`: Input data organized by domain type (optional)
- `prompts/`: System prompt templates for AI workflow automation
- `docs/`: Project documentation including PRDs and proposals
- `pyproject.toml`: Python project configuration with dependencies
- `.env`: Environment variables for API tokens and database IDs
- `.env.example`: Template for environment configuration

### Key Dependencies
- `notion-client>=2.4.0`: For Notion API integration
- `pygithub>=2.6.1`: For GitHub API operations
- `python-dotenv>=1.0.0`: For environment variable management from .env files
- Git-LFS: For managing large result files
- Additional tools may include domain-specific workflow engines (e.g., Nextflow for computational pipelines)

## Output File Management Principles

All outputs follow these management principles:

### A. Git-LFS Management
- **Definition**: Selected core final outputs for papers, reports, PRs
- **Characteristics**: Code-coupled version control essential
- **Examples**: Final result graphs (`final_plot.png`), key statistics (`summary_stats.csv`), final models (`final_model.h5`)
- **Execution**: Use `task add-result` command for Git-LFS tracking with meaningful commit messages

### B. Shared NAS Management  
- **Definition**: Large-scale intermediate/full outputs too large or low-priority for Git
- **Characteristics**: Accessibility and sharing prioritized over version control
- **Examples**: Complete computation `results/` folders, large dataset files, processed outputs
- **Execution**: Configure computation outputs to shared NAS paths initially; record NAS paths as text links in Notion Task anchor pages

### C. Git Exclusions
- **Definition**: Temporary, reproducible files not worth preserving
- **Examples**: Computation work directories, local test logs, cache files
- **Execution**: Specify in project `.gitignore` to completely exclude from Git tracking

## Work Unit Definitions

ëª¨ë“  ì‘ì—… ë‹¨ìœ„ëŠ” **Project â†’ Epic â†’ Task**ì˜ ëª…í™•í•œ ìœ„ê³„ë¥¼ ë”°ë¦…ë‹ˆë‹¤. `/project-plan` ëª…ë ¹ì–´ ì‹¤í–‰ ì‹œ, `prompts/2_create_project_plan.md`ì— ëª…ì‹œëœ ê¸°ì¤€ì„ ë”°ë¼ ì„¸ ë‹¨ìœ„ë¥¼ êµ¬ë¶„í•˜ê³  í˜ì´ì§€ ë‚´ìš©ì„ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

- **Project:** **ì „ëµì  'Why'ì— ë‹µí•˜ëŠ” ë…ë¦½ì ì¸ ê°€ì¹˜ ë‹¨ìœ„ì…ë‹ˆë‹¤.** (ì˜ˆ: ë…¼ë¬¸ í•œ í¸, ì œí’ˆ ì¶œì‹œ)
- **Epic:** **Projectë¥¼ êµ¬ì„±í•˜ëŠ” ê¸°ëŠ¥ì  'What'ì˜ ë¬¶ìŒì…ë‹ˆë‹¤.** (ì˜ˆ: Figure 1 ì œì‘, ì¸ì¦ ì‹œìŠ¤í…œ êµ¬ì¶•)
- **Task:** **Epicì„ ì‹¤í–‰í•˜ëŠ” êµ¬ì²´ì  'How'ì˜ ë‹¨ìœ„ì…ë‹ˆë‹¤.** (ì˜ˆ: íŠ¹ì • ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±, ë°ì´í„° ê²€ì¦)

### Epic Criteria (2+ criteria required)
- **Time**: 2+ weeks completion time?
- **Collaboration**: Multiple assignees needed?
- **Value**: Independent value delivery?
- **Structure**: Clear subdivision into multiple tasks?
- **Communication**: Separate reporting/sharing needed?

### Task Criteria
- **Definition**: Concrete execution units completable by one person within days
- **Page Content**: Include 'Work Objectives', 'Reference Materials', and 'Exploration Journal & Outputs' sections

## Knowledge Creation Workflow

The system follows a 4-stage knowledge creation process detailed in `prompts/1_philosophy_knowledge_creation.md`:

1. **Anchoring (Raw Archive)**: All raw exploration information in Notion Task pages - **`/export` command conversation logs must be preserved in toggle blocks**
2. **AI Summary (1st Restructuring)**: Topic and logic-based information structuring  
3. **Personal Digestion (Full-Stack CREATE)**: Individual insight development and knowledge connection
4. **Team Publication (Core CREATE)**: Final knowledge sharing in Notion Knowledge Hub

### Execution Environment Configuration
When using computational workflow tools, typical execution profiles include:
- `local`: For development and testing (limited resources)  
- `cluster`: For production runs on distributed systems

Always ensure terminal conversation logs are exported and archived in Notion Task toggle blocks using the `/task-archive` slash command.